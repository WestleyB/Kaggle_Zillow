{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Kaggle Zillow Preprocessing Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train_2016_v2.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 64)\n",
      "(90275, 60)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.merge(df_train, prop, on='parcelid', how='left')\n",
    "\n",
    "sample.rename(index=str, columns={'ParcelId': 'parcelid'}, inplace=True)\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "print(df_test.shape)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create features from 'transactiondate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train['transactiondate'] =  pd.to_datetime(df_train['transactiondate'])\n",
    "df_train['transaction_year'] = df_train.transactiondate.dt.year.astype(np.int16)\n",
    "df_train['transaction_month'] = df_train.transactiondate.dt.month.astype(np.int8)\n",
    "df_train['transaction_day'] = df_train.transactiondate.dt.weekday.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create features from 'rawcensustractandblock'\n",
    "BLOCKID:  15-character code that is the concatenation of fields consisting of the 2-character state FIPS code, the 3-character county FIPS code, the 6-character census tract code, and the 4-character tabulation block code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_train['rawcensustractandblock_states'] = df_train.rawcensustractandblock.astype(str).apply(lambda x: x[:1]).astype(np.int8)\n",
    "df_train['rawcensustractandblock_countries'] = df_train.rawcensustractandblock.astype(str).apply(lambda x: x[1:4]).astype(np.int8)\n",
    "df_train['rawcensustractandblock_tracts'] = df_train.rawcensustractandblock.astype(str).apply(lambda x: x[4:11]).astype(np.float64)\n",
    "df_train['rawcensustractandblock_blocks'] = df_train.rawcensustractandblock.astype(str).apply(lambda x: x[11:]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- how old is the house? ---\n",
    "df_train['house_age'] = 2017 - df_train['yearbuilt']\n",
    "\n",
    "#--- how many rooms are there? ---  \n",
    "df_train['tot_rooms'] = df_train['bathroomcnt'] + df_train['bedroomcnt']\n",
    "\n",
    "#--- does the house have A/C? ---\n",
    "df_train['AC'] = np.where(df_train['airconditioningtypeid']>0, 1, 0)\n",
    "\n",
    "#--- Does the house have a deck? ---\n",
    "df_train['deck'] = np.where(df_train['decktypeid']>0, 1, 0)\n",
    "df_train.drop('decktypeid', axis=1, inplace=True)\n",
    "\n",
    "#--- does the house have a heating system? ---\n",
    "df_train['heating_system'] = np.where(df_train['heatingorsystemtypeid']>0, 1, 0)\n",
    "\n",
    "#--- does the house have a garage? ---\n",
    "df_train['garage'] = np.where(df_train['garagecarcnt']>0, 1, 0)\n",
    "\n",
    "#--- does the house come with a patio? ---\n",
    "df_train['patio'] = np.where(df_train['yardbuildingsqft17']>0, 1, 0)\n",
    "\n",
    "#--- does the house have a pool?\n",
    "df_train['pooltypeid10'] = df_train.pooltypeid10.astype(np.int8)\n",
    "df_train['pooltypeid7'] = df_train.pooltypeid7.astype(np.int8)\n",
    "df_train['pooltypei2'] = df_train.pooltypeid2.astype(np.int8)\n",
    "df_train['pool'] = df_train['pooltypeid10'] | df_train['pooltypeid7'] | df_train['pooltypeid2'] \n",
    "\n",
    "#--- does the house have all of these? -> spa/hot-tub/pool, A/C, heating system , garage, patio\n",
    "df_train['exquisite'] = df_train['pool'] + df_train['patio'] + df_train['garage'] + df_train['heating_system'] + df_train['AC'] \n",
    "\n",
    "#--- Features based on location ---\n",
    "df_train['x_loc'] = np.cos(df_train['latitude']) * np.cos(df_train['longitude'])\n",
    "df_train['y_loc'] = np.cos(df_train['latitude']) * np.sin(df_train['longitude'])\n",
    "df_train['z_loc'] = np.sin(df_train['latitude'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MEMORY CONSUMPTION\n",
    "#### Let us look into the memory consumption of our dataframe and see if we can reduce it efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Memory usage of entire dataframe ---\n",
    "mem = df_train.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- List of columns that cannot be reduced in terms of memory size ---\n",
    "count = 0\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == object:\n",
    "        count+=1\n",
    "        print (col)\n",
    "print('There are {} columns that cannot be reduced'.format(count))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype != object:\n",
    "        if((col != 'logerror')|(col != 'yearbuilt')|(col != 'xloc')|(col != 'yloc')|(col != 'zloc')):\n",
    "            if ((df_train[col].max() < 255) & (df_train[col].min() > -255)):\n",
    "                count+=1\n",
    "                df_train[col] = df_train[col].astype(np.int8)\n",
    "                print (col)\n",
    "            if ((df_train[col].max() > 255) & (df_train[col].min() > -255)\n",
    "               & (df_train[col].max() < 65535) & (df_train[col].min() > 0)):\n",
    "                count+=1\n",
    "                df_train[col] = df_train[col].astype(np.int16)\n",
    "                print (col)\n",
    "            if ((df_train[col].max() > 65535) & (df_train[col].min() > 0)\n",
    "               & (df_train[col].max() < 4294967295) & (df_train[col].min() > 0)):\n",
    "                count+=1\n",
    "                df_train[col] = df_train[col].astype(np.int8)\n",
    "                print (col)\n",
    "print('There are {} columns reduced'.format(count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#--- Let us check the memory consumed again ---\n",
    "mem = df_train.memory_usage(index=True).sum()\n",
    "print(mem/ 1024**2,\" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
