{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Zillow XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-17cc20310a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mzillow_new_features\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcreate_newFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_newFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\Desktop\\Kaggle_Zillow\\scripts\\zillow_new_features.py\u001b[0m in \u001b[0;36mcreate_newFeatures\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transactiondate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transactiondate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_year'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransactiondate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from zillow_new_features import create_newFeatures\n",
    "print(len(train.columns))\n",
    "df_train = create_newFeatures(train)\n",
    "print(len(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binding to float32\n",
      "Creating training set ...\n",
      "(90275, 55) (90275,)\n",
      "Building DMatrix...\n",
      "Training ...\n",
      "[0]\ttrain-mae:0.488065\tvalid-mae:0.48112\n",
      "Multiple eval metrics have been passed: 'valid-mae' will be used for early stopping.\n",
      "\n",
      "Will train until valid-mae hasn't improved in 100 rounds.\n",
      "[10]\ttrain-mae:0.402221\tvalid-mae:0.395444\n",
      "[20]\ttrain-mae:0.33268\tvalid-mae:0.326098\n",
      "[30]\ttrain-mae:0.276518\tvalid-mae:0.270132\n",
      "[40]\ttrain-mae:0.231316\tvalid-mae:0.225213\n",
      "[50]\ttrain-mae:0.195059\tvalid-mae:0.189317\n",
      "[60]\ttrain-mae:0.166121\tvalid-mae:0.16072\n",
      "[70]\ttrain-mae:0.143115\tvalid-mae:0.138042\n",
      "[80]\ttrain-mae:0.124973\tvalid-mae:0.120213\n",
      "[90]\ttrain-mae:0.11079\tvalid-mae:0.106351\n",
      "[100]\ttrain-mae:0.099822\tvalid-mae:0.095702\n",
      "[110]\ttrain-mae:0.091454\tvalid-mae:0.087592\n",
      "[120]\ttrain-mae:0.085149\tvalid-mae:0.08158\n",
      "[130]\ttrain-mae:0.080456\tvalid-mae:0.077192\n",
      "[140]\ttrain-mae:0.077015\tvalid-mae:0.074063\n",
      "[150]\ttrain-mae:0.07451\tvalid-mae:0.071827\n",
      "[160]\ttrain-mae:0.072688\tvalid-mae:0.070245\n",
      "[170]\ttrain-mae:0.071374\tvalid-mae:0.069129\n",
      "[180]\ttrain-mae:0.070415\tvalid-mae:0.068366\n",
      "[190]\ttrain-mae:0.069715\tvalid-mae:0.067854\n",
      "[200]\ttrain-mae:0.069209\tvalid-mae:0.067512\n",
      "[210]\ttrain-mae:0.068828\tvalid-mae:0.06727\n",
      "[220]\ttrain-mae:0.068547\tvalid-mae:0.067113\n",
      "[230]\ttrain-mae:0.068334\tvalid-mae:0.067006\n",
      "[240]\ttrain-mae:0.068171\tvalid-mae:0.066937\n",
      "[250]\ttrain-mae:0.068039\tvalid-mae:0.066892\n",
      "[260]\ttrain-mae:0.067937\tvalid-mae:0.066866\n",
      "[270]\ttrain-mae:0.067856\tvalid-mae:0.066848\n",
      "[280]\ttrain-mae:0.067789\tvalid-mae:0.06684\n",
      "[290]\ttrain-mae:0.067735\tvalid-mae:0.066836\n",
      "[300]\ttrain-mae:0.067691\tvalid-mae:0.066838\n",
      "[310]\ttrain-mae:0.067655\tvalid-mae:0.066842\n",
      "[320]\ttrain-mae:0.067618\tvalid-mae:0.066841\n",
      "[330]\ttrain-mae:0.067586\tvalid-mae:0.066845\n",
      "[340]\ttrain-mae:0.067563\tvalid-mae:0.06686\n",
      "[350]\ttrain-mae:0.06754\tvalid-mae:0.066865\n",
      "[360]\ttrain-mae:0.067518\tvalid-mae:0.066872\n",
      "[370]\ttrain-mae:0.0675\tvalid-mae:0.066875\n",
      "[380]\ttrain-mae:0.067482\tvalid-mae:0.066877\n",
      "Stopping. Best iteration:\n",
      "[288]\ttrain-mae:0.067745\tvalid-mae:0.066835\n",
      "\n",
      "Building test set ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test ...\n",
      "Writing csv ...\n"
     ]
    }
   ],
   "source": [
    "print('Loading data ...')\n",
    "\n",
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "print('Binding to float32')\n",
    "\n",
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)\n",
    "\n",
    "print('Creating training set ...')\n",
    "\n",
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "split = 80000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "\n",
    "print('Building DMatrix...')\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "del x_train, x_valid; gc.collect()\n",
    "\n",
    "print('Training ...')\n",
    "\n",
    "params = {}\n",
    "params['eta'] = 0.02\n",
    "params['objective'] = 'reg:linear'\n",
    "params['eval_metric'] = 'mae'\n",
    "params['max_depth'] = 4\n",
    "params['silent'] = 1\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "del d_train, d_valid\n",
    "\n",
    "print('Building test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "del prop; gc.collect()\n",
    "\n",
    "x_test = df_test[train_columns]\n",
    "for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "    x_test[c] = (x_test[c] == True)\n",
    "\n",
    "del df_test, sample; gc.collect()\n",
    "\n",
    "d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "del x_test; gc.collect()\n",
    "\n",
    "print('Predicting on test ...')\n",
    "\n",
    "p_test = clf.predict(d_test)\n",
    "\n",
    "del d_test; gc.collect()\n",
    "\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test\n",
    "\n",
    "print('Writing csv ...')\n",
    "sub.to_csv('xgb_starter.csv', index=False, float_format='%.4f') # Thanks to @inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
