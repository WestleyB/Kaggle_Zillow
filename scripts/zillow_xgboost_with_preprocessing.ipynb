{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kaggle Zillow Preprocessing + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 0.0660352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sami_function import missing_ratio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from sklearn import linear_model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_newFeatures(dataframe):\n",
    "    \"\"\"\n",
    "    Create new features for Zillow dataframe\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if 'transactiondate' in dataframe.columns:\n",
    "        dataframe['transactiondate'] =  pd.to_datetime(dataframe['transactiondate'])\n",
    "        dataframe['transaction_year'] = dataframe.transactiondate.dt.year.astype(np.int16)\n",
    "        dataframe['transaction_month'] = dataframe.transactiondate.dt.month.astype(np.int8)\n",
    "        # dataframe['transaction_day'] = dataframe.transactiondate.dt.weekday.astype(np.int8)\n",
    "        # dataframe['transaction_quarter'] = dataframe.transactiondate.dt.quarter.astype(np.int8)\n",
    "        del dataframe['transactiondate']\n",
    "    else:\n",
    "        df_date = pd.DataFrame({'transaction_year': [2016, 2016, 2016, 2017, 2017, 2017],\n",
    "                             'transaction_month': [10, 11, 12, 10, 11, 12]})\n",
    "        df_date['tmp'] = 1\n",
    "        dataframe['tmp'] = 1\n",
    "        dataframe = pd.merge(dataframe, df_date, on='tmp')\n",
    "        del dataframe['tmp']\n",
    "        # dataframe['transaction_quarter'] = str(str(dataframe['transaction_year'])+'-'+str(dataframe['transaction_month'])+'-01')\n",
    "        # dataframe['transaction_quarter'] = pd.to_datetime(dataframe['transaction_quarter']).dt.quarter.astype(np.int8)\n",
    "                             \n",
    "    dataframe['rawcensustractandblock_states'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[:1]).astype(np.int8)\n",
    "    dataframe['rawcensustractandblock_countries'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[1:4]).astype(np.int8)\n",
    "    dataframe['rawcensustractandblock_tracts'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[4:11]).astype(np.float64)\n",
    "    dataframe['rawcensustractandblock_blocks'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: 0 if x[11:] == '' else x[11:]).astype(np.int8)\n",
    "    \n",
    "    #--- how old is the house? ---\n",
    "    dataframe['yearbuilt'] = dataframe['yearbuilt'].fillna(2016).astype(np.int16)\n",
    "    dataframe['house_age'] = dataframe['transaction_year'].astype(np.int16) - dataframe['yearbuilt'].astype(np.int16)\n",
    "\n",
    "    #--- how many rooms are there? ---\n",
    "    dataframe['bathroomcnt'] = dataframe['bathroomcnt'].fillna(1)\n",
    "    dataframe['bedroomcnt'] = dataframe['bedroomcnt'].fillna(1)\n",
    "    dataframe['tot_rooms'] = dataframe['bathroomcnt'] + dataframe['bedroomcnt']\n",
    "\n",
    "    #--- does the house have A/C? ---\n",
    "    dataframe['airconditioningtypeid'] = dataframe['airconditioningtypeid'].fillna(5)\n",
    "    dataframe['AC'] = np.where(dataframe['airconditioningtypeid']>0, 1, 0)\n",
    "\n",
    "    #--- Does the house have a deck? ---\n",
    "    dataframe['decktypeid'] = dataframe['decktypeid'].fillna(0)\n",
    "    dataframe['deck'] = np.where(dataframe['decktypeid']>0, 1, 0)\n",
    "    dataframe.drop('decktypeid', axis=1, inplace=True)\n",
    "\n",
    "    #--- does the house have a heating system? ---\n",
    "    dataframe['heatingorsystemtypeid'] = dataframe['heatingorsystemtypeid'].fillna(13)\n",
    "    dataframe['heating_system'] = np.where(dataframe['heatingorsystemtypeid']>0, 1, 0)\n",
    "\n",
    "    #--- does the house have a garage? ---\n",
    "    dataframe['garagecarcnt'] = dataframe['garagecarcnt'].fillna(0)\n",
    "    dataframe['garage'] = np.where(dataframe['garagecarcnt']>0, 1, 0)\n",
    "\n",
    "    #--- does the house come with a patio? ---\n",
    "    dataframe['yardbuildingsqft17'] = dataframe['yardbuildingsqft17'].fillna(0)\n",
    "    dataframe['patio'] = np.where(dataframe['yardbuildingsqft17']>0, 1, 0)\n",
    "\n",
    "    #--- does the house have a pool?\n",
    "    dataframe['pooltypeid10'] = dataframe.pooltypeid10.fillna(0).astype(np.int8)\n",
    "    dataframe['pooltypeid7'] = dataframe.pooltypeid7.fillna(0).astype(np.int8)\n",
    "    dataframe['pooltypei2'] = dataframe.pooltypeid2.fillna(0).astype(np.int8)\n",
    "    dataframe['pool'] = dataframe['pooltypeid10'] | dataframe['pooltypeid7'] | dataframe['pooltypeid2']\n",
    "\n",
    "    #--- does the house have all of these? -> spa/hot-tub/pool, A/C, heating system , garage, patio\n",
    "    dataframe['exquisite'] = dataframe['pool'] + dataframe['patio'] + dataframe['garage'] + dataframe['heating_system'] + dataframe['AC']\n",
    "\n",
    "    #--- Features based on location ---\n",
    "    dataframe['x_loc'] = np.cos(dataframe['latitude']) * np.cos(dataframe['longitude'])\n",
    "    dataframe['y_loc'] = np.cos(dataframe['latitude']) * np.sin(dataframe['longitude'])\n",
    "    dataframe['z_loc'] = np.sin(dataframe['latitude'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory_reduce(dataframe):\n",
    "\n",
    "    #--- Memory usage of entire dataframe ---\n",
    "    mem = dataframe.memory_usage(index=True).sum()\n",
    "    print(\"Initial size {:.2f} MB\".format(mem/ 1024**2))\n",
    "\n",
    "    #--- List of columns that cannot be reduced in terms of memory size ---\n",
    "    count = 0\n",
    "    for c in dataframe.columns:\n",
    "        if dataframe[c].dtype == object:\n",
    "            count+=1\n",
    "    print('There are {} columns that cannot be reduced'.format(count))\n",
    "\n",
    "    count = 0\n",
    "    for c in dataframe.columns:\n",
    "\n",
    "        if dataframe[c].dtype in ['int8', 'int16', 'int32', 'int64']:\n",
    "            \n",
    "            if (np.iinfo(np.int8).min < dataframe[c].min()) and (dataframe[c].max() < np.iinfo(np.int8).max):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.int8)\n",
    "            \n",
    "            if (np.iinfo(np.int16).min < dataframe[c].min()) and (dataframe[c].max() < np.iinfo(np.int16).max) and ((np.iinfo(np.int8).min > dataframe[c].min()) or (dataframe[c].max() > np.iinfo(np.int8).max)):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.int16)\n",
    "            \n",
    "            if (np.iinfo(np.int32).min < dataframe[c].min()) and (dataframe[c].max() < np.iinfo(np.int32).max) and ((np.iinfo(np.int16).min > dataframe[c].min()) or (dataframe[c].max() > np.iinfo(np.int16).max)):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.int32)\n",
    "            \n",
    "            if (np.iinfo(np.int64).min < dataframe[c].min()) and (dataframe[c].max() < np.iinfo(np.int64).max) and ((np.iinfo(np.int32).min > dataframe[c].min()) or (dataframe[c].max() > np.iinfo(np.int32).max)):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.int64)\n",
    "\n",
    "        if dataframe[c].dtype in ['float16', 'float32', 'float64']:\n",
    "            \n",
    "            if (np.finfo(np.float16).min < dataframe[c].min()) and (dataframe[c].max() < np.finfo(np.float16).max):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.float16)\n",
    "            \n",
    "            if (np.finfo(np.float32).min < dataframe[c].min()) and (dataframe[c].max() < np.finfo(np.float32).max) and ((np.finfo(np.float16).min > dataframe[c].min()) or (dataframe[c].max() > np.finfo(np.float16).max)):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.float32)\n",
    "            \n",
    "            if (np.finfo(np.float64).min < dataframe[c].min()) and (dataframe[c].max() < np.finfo(np.float64).max) and ((np.finfo(np.float32).min > dataframe[c].min()) or (dataframe[c].max() > np.finfo(np.float32).max)):\n",
    "                count+=1\n",
    "                dataframe[c] = dataframe[c].fillna(0).astype(np.float64)\n",
    "\n",
    "    print('There are {} columns reduced'.format(count))\n",
    "\n",
    "    #--- Let us check the memory consumed again ---\n",
    "    mem = dataframe.memory_usage(index=True).sum()\n",
    "    print(\"Final size {:.2f} MB\".format(mem/ 1024**2))\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(dataframe):\n",
    "    \n",
    "    dataframe['rawcensustractandblock'] = dataframe.rawcensustractandblock.fillna(dataframe.rawcensustractandblock.mode()[0])\n",
    "    \n",
    "    dataframe['buildingclasstypeid'] = dataframe['buildingclasstypeid'].fillna(dataframe['buildingclasstypeid'].mode()[0])\n",
    "    dataframe['storytypeid'] = dataframe['storytypeid'].fillna(dataframe['storytypeid'].mode()[0])\n",
    "    dataframe['architecturalstyletypeid'] = dataframe['architecturalstyletypeid'].fillna(dataframe['architecturalstyletypeid'].mode()[0])\n",
    "    dataframe['typeconstructiontypeid'] = dataframe['typeconstructiontypeid'].fillna(dataframe['typeconstructiontypeid'].mode()[0])\n",
    "\n",
    "    dataframe['taxdelinquencyyear'] = dataframe['taxdelinquencyyear'].fillna(15).astype(np.int8)\n",
    "    dataframe['taxdelinquencyyear'] = np.where(dataframe.taxdelinquencyyear < 18, 2000 + dataframe.taxdelinquencyyear.astype(np.int16), 1900 + dataframe.taxdelinquencyyear.astype(np.int16)).astype(np.int16)\n",
    "\n",
    "    dataframe['taxamount'] = dataframe['taxamount'].fillna(dataframe['taxamount'].mean())\n",
    "\n",
    "    for c in dataframe.columns:\n",
    "        if 'squarefeet' in c or 'sqft' in c or 'size' in c or 'pooltypeid' in c or 'cnt' in c or 'nbr' in c or 'number' in c:\n",
    "            dataframe[c] = dataframe[c].fillna(0)\n",
    "    \n",
    "    #--- drop out ouliers ---\n",
    "#     dataframe = dataframe[dataframe['logerror'] > -0.4 ]\n",
    "#     dataframe = dataframe[dataframe['logerror'] < 0.4 ]\n",
    "    \n",
    "#     # replace or drop values ???\n",
    "#     for c in dataframe.columns:\n",
    "#         if c == 'logerror':\n",
    "#             ulimit = np.percentile(dataframe[c].values, 99)\n",
    "#             llimit = np.percentile(dataframe[c].values, 1)\n",
    "#             dataframe.loc[dataframe[c] > ulimit, [c]] = ulimit\n",
    "#             dataframe.loc[dataframe[c] < llimit, [c]] = llimit\n",
    "    \n",
    "    for c in dataframe.dtypes[dataframe.dtypes == object].index.values:\n",
    "        if len(dataframe[c].unique()) <= 2:\n",
    "            dataframe[c] = dataframe[c].map({True: 1, 'Y': 1})\n",
    "            dataframe[c] = dataframe[c].fillna(0)\n",
    "            dataframe[c] = dataframe[c].astype(np.int8)\n",
    "        else:\n",
    "            dataframe[c] = dataframe[c].fillna(1)\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(dataframe[c].values))\n",
    "            dataframe[c] = lbl.transform(list(dataframe[c].values)).astype(np.int8)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating new features ...\n",
      "Shape train: (90275, 60)\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 41.84 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 76 columns reduced\n",
      "Final size 14.64 MB\n",
      "\n",
      "Creating training set ...\n",
      "(90275, 76) (90275,)\n",
      "\n",
      "Building DMatrix...\n",
      "\n",
      "Training ...\n",
      "[0]\ttrain-mae:0.0684124\ttest-mae:0.0684197\n",
      "[10]\ttrain-mae:0.0681056\ttest-mae:0.0682036\n",
      "[20]\ttrain-mae:0.0679405\ttest-mae:0.0681218\n",
      "[30]\ttrain-mae:0.0678438\ttest-mae:0.0681107\n",
      "[40]\ttrain-mae:0.067768\ttest-mae:0.0681024\n",
      "[50]\ttrain-mae:0.0677012\ttest-mae:0.0681133\n",
      "[60]\ttrain-mae:0.0676389\ttest-mae:0.0681251\n",
      "[70]\ttrain-mae:0.0675867\ttest-mae:0.0681393\n",
      "[80]\ttrain-mae:0.0675326\ttest-mae:0.0681553\n",
      "[90]\ttrain-mae:0.0674807\ttest-mae:0.0681713\n",
      "[100]\ttrain-mae:0.0674322\ttest-mae:0.0681881\n",
      "[110]\ttrain-mae:0.0673908\ttest-mae:0.0682067\n",
      "[120]\ttrain-mae:0.0673463\ttest-mae:0.068227\n",
      "[130]\ttrain-mae:0.0673073\ttest-mae:0.0682564\n",
      "\n",
      "\tMAE 0.06810240000000001 for 40 rounds\n",
      "\n",
      "Building test set ...\n",
      "\n",
      "Working batch 100000\n",
      "\n",
      "Creating new features ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown string format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[1;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtslib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime_to_datetime64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.datetime_to_datetime64 (pandas\\_libs\\tslib.c:33275)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unrecognized value type: <class 'str'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d429e5a809e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'print(\\'\\\\nLoading data ...\\')\\n\\ntrain =  pd.read_csv(\\'../data/train_2016_v2.csv\\')\\nprop = pd.read_csv(\\'../data/properties_2016.csv\\')\\nsample = pd.read_csv(\\'../data/sample_submission.csv\\')\\n\\n\\nprint(\\'\\\\nCreating new features ...\\')\\n\\ndf_train = pd.merge(train, prop, on=\\'parcelid\\', how=\\'left\\')\\nprint(\\'Shape train: {}\\'.format(df_train.shape))\\n\\ndel train; gc.collect()\\n\\ndf_train = create_newFeatures(df_train)\\n\\n\\nprint(\\'\\\\nData preprocessing ...\\')\\n\\ndf_train = data_preprocessing(df_train)\\n\\n\\nprint(\\'\\\\nReducing consumption memory ...\\')\\n\\ndf_train = memory_reduce(df_train)\\n\\n# print(\\'\\\\nDropping columns ...\\')\\n\\n# col_2_drop = list(missing_ratio(df_train, plot=False).index)\\n# df_train = df_train.drop(col_2_drop, axis=1)\\n\\nprint(\\'\\\\nCreating training set ...\\')\\n\\nx_train = df_train.drop([\\'parcelid\\', \\'logerror\\'], axis=1)  # , \\'propertyzoningdesc\\', \\'propertycountylandusecode\\'\\ny_train = df_train[\\'logerror\\'].values\\nprint(x_train.shape, y_train.shape)\\n\\ny_mean = np.mean(y_train)\\ntrain_columns = x_train.columns\\n    \\ndel df_train; gc.collect()\\n\\n# split = 80000\\n# x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\\n# # x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.12, random_state=seed)\\n\\nprint(\\'\\\\nBuilding DMatrix...\\')\\n\\n# d_train = xgb.DMatrix(x_train, label=y_train)\\n# d_valid = xgb.DMatrix(x_valid, label=y_valid)\\n\\n# del x_train, x_valid; gc.collect()\\n\\nd_train = xgb.DMatrix(x_train, y_train)\\n\\ndel x_train; gc.collect()\\n\\nprint(\\'\\\\nTraining ...\\')\\n\\nparams = {\\n    \\'eta\\': 0.03,\\n    \\'max_depth\\': 5,\\n    \\'subsample\\': 0.80,\\n    \\'objective\\': \\'reg:linear\\',\\n    \\'eval_metric\\': \\'mae\\',\\n    \\'base_score\\': y_mean,\\n    \\'silent\\': 1,\\n    \\'seed\\': seed\\n}\\n\\n#--- cross-validation ---\\ncv_result = xgb.cv(\\n                    params, \\n                    d_train, \\n                    nfold=10,\\n                    num_boost_round=1000,\\n                    early_stopping_rounds=100,\\n                    verbose_eval=10, \\n                    show_stdv=False\\n                  )\\n\\nnum_boost_rounds = cv_result[\\'test-mae-mean\\'].argmin()\\nmean_mae = cv_result[\\'test-mae-mean\\'].min()\\n\\nprint(\"\\\\n\\\\tMAE {} for {} rounds\".format(mean_mae, num_boost_rounds))\\n\\n\\n#--- train model ---\\nclf = xgb.train(dict(params), d_train, num_boost_round=num_boost_rounds)\\n\\n# watchlist = [(d_train, \\'train\\'), (d_valid, \\'valid\\')]\\n# clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\\n\\n\\n# del d_train, d_valid\\ndel d_train\\n\\nprint(\\'\\\\nBuilding test set ...\\')\\n\\nsample[\\'parcelid\\'] = sample[\\'ParcelId\\']\\ndf_test = sample.merge(prop, on=\\'parcelid\\', how=\\'left\\')\\n\\ndel prop, sample; gc.collect()\\n\\np_test = []\\nbatch_size = 100000\\nfor batch in range(batch_size, df_test.shape[0]+batch_size, batch_size):\\n    \\n    print(\\'\\\\nWorking batch {}\\'.format(batch))\\n    \\n    df_test_batch = df_test[batch-batch_size:batch].copy()\\n    \\n    print(\\'\\\\nCreating new features ...\\')\\n    \\n    df_test_batch[\\'rawcensustractandblock\\'] = df_test_batch.rawcensustractandblock.fillna(df_test.rawcensustractandblock.mode()[0])\\n    df_test_batch = df_test_batch.fillna(0)\\n    \\n    df_test_batch = create_newFeatures(df_test_batch)\\n    \\n    print(\\'\\\\nData preprocessing ...\\')\\n\\n    df_test_batch = data_preprocessing(df_test_batch)\\n\\n\\n    print(\\'\\\\nReducing consumption memory ...\\')\\n    \\n    df_test_batch = memory_reduce(df_test_batch)\\n\\n    x_test = df_test_batch[train_columns]\\n\\n    del df_test_batch; gc.collect()\\n\\n    d_test = xgb.DMatrix(x_test)\\n\\n    del x_test; gc.collect()\\n\\n    print(\\'\\\\nPredicting on test ...\\')\\n\\n    p_test_batch = clf.predict(d_test)\\n\\n    del d_test; gc.collect()\\n    \\n    [p_test.append(p) for p in p_test_batch]\\n\\ni = 0\\nsub = pd.read_csv(\\'../data/sample_submission.csv\\')\\nfor c in sub.columns[sub.columns != \\'ParcelId\\']:\\n    sub[c] = p_test[i::6]\\n    i = i + 1\\n\\nprint(\\'\\\\nWriting csv ...\\')\\nsub.to_csv(\\'../submissions/xgb_{}.csv\\'.format(datetime.now().strftime(\\'%Y%m%d_%H%M%S\\')), index=False, float_format=\\'%.4f\\')\\n\\nprint(\\'\\\\nPrediction available !!!\\')'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8e6b472630db>\u001b[0m in \u001b[0;36mcreate_newFeatures\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tmp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_quarter'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_month'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-01'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_quarter'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'transaction_quarter'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquarter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rawcensustractandblock_states'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawcensustractandblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, box, format, exact, unit, infer_datetime_format, origin)\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_convert_listlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMutableMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[1;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\u001b[0m in \u001b[0;36m_convert_listlike\u001b[1;34m(arg, box, format, name, tz)\u001b[0m\n\u001b[0;32m    433\u001b[0m                     \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdayfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                     \u001b[0myearfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myearfirst\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                     \u001b[0mrequire_iso8601\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequire_iso8601\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m                 )\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime (pandas\\_libs\\tslib.c:46617)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime (pandas\\_libs\\tslib.c:46233)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.array_to_datetime (pandas\\_libs\\tslib.c:46122)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslib.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslib.parse_datetime_string (pandas\\_libs\\tslib.c:35351)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\dateutil\\parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[0;32m   1166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparserinfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDEFAULTPARSER\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\dateutil\\parser.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown string format\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown string format"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('\\nLoading data ...')\n",
    "\n",
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "\n",
    "print('\\nCreating new features ...')\n",
    "\n",
    "df_train = pd.merge(train, prop, on='parcelid', how='left')\n",
    "print('Shape train: {}'.format(df_train.shape))\n",
    "\n",
    "del train; gc.collect()\n",
    "\n",
    "df_train = create_newFeatures(df_train)\n",
    "\n",
    "\n",
    "print('\\nData preprocessing ...')\n",
    "\n",
    "df_train = data_preprocessing(df_train)\n",
    "\n",
    "\n",
    "print('\\nReducing consumption memory ...')\n",
    "\n",
    "df_train = memory_reduce(df_train)\n",
    "\n",
    "# print('\\nDropping columns ...')\n",
    "\n",
    "# col_2_drop = list(missing_ratio(df_train, plot=False).index)\n",
    "# df_train = df_train.drop(col_2_drop, axis=1)\n",
    "\n",
    "print('\\nCreating training set ...')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror'], axis=1)  # , 'propertyzoningdesc', 'propertycountylandusecode'\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "y_mean = np.mean(y_train)\n",
    "train_columns = x_train.columns\n",
    "    \n",
    "del df_train; gc.collect()\n",
    "\n",
    "# split = 80000\n",
    "# x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "# # x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.12, random_state=seed)\n",
    "\n",
    "print('\\nBuilding DMatrix...')\n",
    "\n",
    "# d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "# d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "# del x_train, x_valid; gc.collect()\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, y_train)\n",
    "\n",
    "del x_train; gc.collect()\n",
    "\n",
    "print('\\nTraining ...')\n",
    "\n",
    "params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1,\n",
    "    'seed': seed\n",
    "}\n",
    "\n",
    "#--- cross-validation ---\n",
    "cv_result = xgb.cv(\n",
    "                    params, \n",
    "                    d_train, \n",
    "                    nfold=10,\n",
    "                    num_boost_round=1000,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=10, \n",
    "                    show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = cv_result['test-mae-mean'].argmin()\n",
    "mean_mae = cv_result['test-mae-mean'].min()\n",
    "\n",
    "print(\"\\n\\tMAE {} for {} rounds\".format(mean_mae, num_boost_rounds))\n",
    "\n",
    "\n",
    "#--- train model ---\n",
    "clf = xgb.train(dict(params), d_train, num_boost_round=num_boost_rounds)\n",
    "\n",
    "# watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "# clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "\n",
    "# del d_train, d_valid\n",
    "del d_train\n",
    "\n",
    "print('\\nBuilding test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "del prop, sample; gc.collect()\n",
    "\n",
    "p_test = []\n",
    "batch_size = 100000\n",
    "for batch in range(batch_size, df_test.shape[0]+batch_size, batch_size):\n",
    "    \n",
    "    print('\\nWorking batch {}'.format(batch))\n",
    "    \n",
    "    df_test_batch = df_test[batch-batch_size:batch].copy()\n",
    "    \n",
    "    print('\\nCreating new features ...')\n",
    "    \n",
    "    df_test_batch['rawcensustractandblock'] = df_test_batch.rawcensustractandblock.fillna(df_test.rawcensustractandblock.mode()[0])\n",
    "    df_test_batch = df_test_batch.fillna(0)\n",
    "    \n",
    "    df_test_batch = create_newFeatures(df_test_batch)\n",
    "    \n",
    "    print('\\nData preprocessing ...')\n",
    "\n",
    "    df_test_batch = data_preprocessing(df_test_batch)\n",
    "\n",
    "\n",
    "    print('\\nReducing consumption memory ...')\n",
    "    \n",
    "    df_test_batch = memory_reduce(df_test_batch)\n",
    "\n",
    "    x_test = df_test_batch[train_columns]\n",
    "\n",
    "    del df_test_batch; gc.collect()\n",
    "\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "    del x_test; gc.collect()\n",
    "\n",
    "    print('\\nPredicting on test ...')\n",
    "\n",
    "    p_test_batch = clf.predict(d_test)\n",
    "\n",
    "    del d_test; gc.collect()\n",
    "    \n",
    "    [p_test.append(p) for p in p_test_batch]\n",
    "\n",
    "i = 0\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test[i::6]\n",
    "    i = i + 1\n",
    "\n",
    "print('\\nWriting csv ...')\n",
    "sub.to_csv('../submissions/xgb_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')\n",
    "\n",
    "print('\\nPrediction available !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
