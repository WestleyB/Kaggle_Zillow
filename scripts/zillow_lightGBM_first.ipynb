{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Zillow Algo LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 0.0644038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "import datetime as dt\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Memory usage reduction...\n",
      "Feature engineering...\n",
      "Preparing arrays and throwing out outliers...\n",
      "Training LGBM model...\n",
      "Making predictions and praying for good results...\n",
      "5% completed\n",
      "10% completed\n",
      "15% completed\n",
      "20% completed\n",
      "25% completed\n",
      "30% completed\n",
      "35% completed\n",
      "40% completed\n",
      "45% completed\n",
      "50% completed\n",
      "55% completed\n",
      "60% completed\n",
      "65% completed\n",
      "70% completed\n",
      "75% completed\n",
      "80% completed\n",
      "85% completed\n",
      "90% completed\n",
      "95% completed\n",
      "100% completed\n",
      "Saving predictions...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-56746dd391dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../submissions/light-lgb_{}.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d_%H%M%S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'%.4f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "## Version 3 - LB 0.0644042\n",
    "# Train month averages for test predictions seem work better than their linear fit,\n",
    "# so I changed it (overfitting test data as hell... but who doesn't here? ;))\n",
    "\n",
    "## Version 2 - LB 0.0644120\n",
    "# LGBM performs much better, so I left him alone\n",
    "\n",
    "## Version 1 - LB 0.0644711\n",
    "# Both models have the same weight, which is based on cross-validation results, but\n",
    "# XGB model seems to be worse on public LB, 'cause alone gets score 0.0646474,\n",
    "# which is much worse than score of the combination. I reached the limit of submissions,\n",
    "# so I will check how LGBM alone performs tomorrow. Check it out for your own ;)\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "properties = pd.read_csv('../data/properties_2016.csv', low_memory = False)\n",
    "train = pd.read_csv('../data/train_2016_v2.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv', low_memory = False)\n",
    "\n",
    "train = pd.merge(train, properties, how = 'left', on = 'parcelid')\n",
    "test = pd.merge(sample_submission[['ParcelId']], properties.rename(columns = {'parcelid': 'ParcelId'}), \n",
    "                how = 'left', on = 'ParcelId')\n",
    "\n",
    "del properties\n",
    "gc.collect();\n",
    "\n",
    "\n",
    "print('Memory usage reduction...')\n",
    "train[['latitude', 'longitude']] /= 1e6\n",
    "test[['latitude', 'longitude']] /= 1e6\n",
    "\n",
    "train['censustractandblock'] /= 1e12\n",
    "test['censustractandblock'] /= 1e12\n",
    "\n",
    "for column in test.columns:\n",
    "    if test[column].dtype == int:\n",
    "        test[column] = test[column].astype(np.int32)\n",
    "    if test[column].dtype == float:\n",
    "        test[column] = test[column].astype(np.float32)\n",
    "      \n",
    "        \n",
    "print('Feature engineering...')\n",
    "train['month'] = pd.to_datetime(train['transactiondate']).dt.month\n",
    "train = train.drop('transactiondate', axis = 1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "non_number_columns = train.dtypes[train.dtypes == object].index.values\n",
    "\n",
    "for column in non_number_columns:\n",
    "    train_test = pd.concat([train[column], test[column]], axis = 0)\n",
    "    encoder = LabelEncoder().fit(train_test.astype(str))\n",
    "    train[column] = encoder.transform(train[column].astype(str)).astype(np.int32)\n",
    "    test[column] = encoder.transform(test[column].astype(str)).astype(np.int32)\n",
    "    \n",
    "feature_names = train.columns[2:]\n",
    "feature_names = [feature for feature in feature_names if feature != 'month']\n",
    "\n",
    "month_avgs = train.groupby('month').agg(['mean'])['logerror', 'mean'].values - train['logerror'].mean()\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "month_model = LinearRegression().fit(np.arange(4, 13, 1).reshape(-1, 1), \n",
    "                                     month_avgs[3:].reshape(-1, 1))\n",
    "                             \n",
    "                             \n",
    "print('Preparing arrays and throwing out outliers...')\n",
    "X_train = train[feature_names].values\n",
    "y_train = train.iloc[:, 1].values\n",
    "X_test = test[feature_names].values\n",
    "\n",
    "del test\n",
    "gc.collect();\n",
    "\n",
    "month_values = train['month'].values\n",
    "X_train = np.hstack([X_train, month_model.predict(month_values.reshape(-1, 1))])\n",
    "\n",
    "X_train = X_train[np.abs(y_train) < 0.4, :]\n",
    "y_train = y_train[np.abs(y_train) < 0.4]\n",
    "\n",
    "\n",
    "print('Training LGBM model...')\n",
    "ltrain = lgb.Dataset(X_train, label = y_train)\n",
    "\n",
    "params = {}\n",
    "params['metric'] = 'mae'\n",
    "params['max_depth'] = 100\n",
    "params['num_leaves'] = 32\n",
    "params['feature_fraction'] = .85\n",
    "params['bagging_fraction'] = .95\n",
    "params['bagging_freq'] = 8\n",
    "params['learning_rate'] = 0.0025\n",
    "params['verbosity'] = 0\n",
    "\n",
    "lgb_model = lgb.train(params, ltrain, verbose_eval=0, num_boost_round=2930)\n",
    "                  \n",
    "                  \n",
    "print('Making predictions and praying for good results...')\n",
    "X_test = np.hstack([X_test, np.zeros((X_test.shape[0], 1))])\n",
    "folds = 20\n",
    "n = int(X_test.shape[0] / folds)\n",
    "\n",
    "for j in range(folds):\n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    if j < folds - 1:\n",
    "            X_test_ = X_test[j*n: (j+1)*n, :]\n",
    "            results['ParcelId'] = sample_submission['ParcelId'].iloc[j*n: (j+1)*n]\n",
    "    else:\n",
    "            X_test_ = X_test[j*n: , :]\n",
    "            results['ParcelId'] = sample_submission['ParcelId'].iloc[j*n: ]\n",
    "            \n",
    "    for month in [10, 11, 12]:\n",
    "        X_test_[:, -1] = month_avgs[month - 1]\n",
    "        assert X_test_.shape[1] == X_test.shape[1]\n",
    "        y_pred = lgb_model.predict(X_test_)\n",
    "        results['2016' + str(month)] = y_pred\n",
    "        results['2017' + str(month)] = y_pred\n",
    "        \n",
    "    if j == 0:\n",
    "        results_ = results.copy()\n",
    "    else:\n",
    "        results_ = pd.concat([results_, results], axis = 0)\n",
    "    print('{}% completed'.format(round(100*(j+1)/folds)))\n",
    "    \n",
    "    \n",
    "print('Saving predictions...')\n",
    "results = results_[sample_submission.columns]\n",
    "assert results.shape == sample_submission.shape\n",
    "results.to_csv('../submissions/light-gbm_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Saving predictions...')\n",
    "results = results_[sample_submission.columns]\n",
    "assert results.shape == sample_submission.shape\n",
    "results.to_csv('../submissions/light-lgb_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
