{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kaggle Zillow Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sami_function import missing_ratio\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_newFeatures(dataframe):\n",
    "    \"\"\"\n",
    "    Create new features for Zillow dataframe\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if 'transactiondate' in dataframe.columns:\n",
    "        dataframe['transactiondate'] =  pd.to_datetime(dataframe['transactiondate'])\n",
    "        dataframe['transaction_year'] = dataframe.transactiondate.dt.year.astype(np.int16)\n",
    "        dataframe['transaction_month'] = dataframe.transactiondate.dt.month.astype(np.int8)\n",
    "        # dataframe['transaction_day'] = dataframe.transactiondate.dt.weekday.astype(np.int8)\n",
    "        # dataframe['transaction_quarter'] = dataframe.transactiondate.dt.quarter.astype(np.int8)\n",
    "        del dataframe['transactiondate']\n",
    "    else:\n",
    "        df_date = pd.DataFrame({'transaction_year': [2016, 2016, 2016, 2017, 2017, 2017],\n",
    "                             'transaction_month': [10, 11, 12, 10, 11, 12]})\n",
    "        df_date['tmp'] = 1\n",
    "        dataframe['tmp'] = 1\n",
    "        dataframe = pd.merge(dataframe, df_date, on='tmp')\n",
    "        del dataframe['tmp']\n",
    "                             \n",
    "    dataframe['rawcensustractandblock_states'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[:1]).astype(np.int8)\n",
    "    dataframe['rawcensustractandblock_countries'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[1:4]).astype(np.int8)\n",
    "    dataframe['rawcensustractandblock_tracts'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: x[4:11]).astype(np.float64)\n",
    "    dataframe['rawcensustractandblock_blocks'] = dataframe.rawcensustractandblock.astype(str).apply(lambda x: 0 if x[11:] == '' else x[11:]).astype(np.int8)\n",
    "    \n",
    "    #--- how old is the house? ---\n",
    "    dataframe['yearbuilt'] = dataframe['yearbuilt'].fillna(2016).astype(np.int16)\n",
    "    dataframe['house_age'] = dataframe['transaction_year'].astype(np.int16) - dataframe['yearbuilt'].astype(np.int16)\n",
    "\n",
    "    #--- how many rooms are there? ---\n",
    "    dataframe['bathroomcnt'] = dataframe['bathroomcnt'].fillna(1)\n",
    "    dataframe['bedroomcnt'] = dataframe['bedroomcnt'].fillna(1)\n",
    "    dataframe['tot_rooms'] = dataframe['bathroomcnt'] + dataframe['bedroomcnt']\n",
    "\n",
    "    #--- does the house have A/C? ---\n",
    "    dataframe['airconditioningtypeid'] = dataframe['airconditioningtypeid'].fillna(5)\n",
    "    dataframe['AC'] = np.where(dataframe['airconditioningtypeid']>0, 1, 0)\n",
    "\n",
    "    #--- Does the house have a deck? ---\n",
    "    dataframe['decktypeid'] = dataframe['decktypeid'].fillna(0)\n",
    "    dataframe['deck'] = np.where(dataframe['decktypeid']>0, 1, 0)\n",
    "    dataframe.drop('decktypeid', axis=1, inplace=True)\n",
    "\n",
    "    #--- does the house have a heating system? ---\n",
    "    dataframe['heatingorsystemtypeid'] = dataframe['heatingorsystemtypeid'].fillna(13)\n",
    "    dataframe['heating_system'] = np.where(dataframe['heatingorsystemtypeid']>0, 1, 0)\n",
    "\n",
    "    #--- does the house have a garage? ---\n",
    "    dataframe['garagecarcnt'] = dataframe['garagecarcnt'].fillna(0)\n",
    "    dataframe['garage'] = np.where(dataframe['garagecarcnt']>0, 1, 0)\n",
    "\n",
    "    #--- does the house come with a patio? ---\n",
    "    dataframe['yardbuildingsqft17'] = dataframe['yardbuildingsqft17'].fillna(0)\n",
    "    dataframe['patio'] = np.where(dataframe['yardbuildingsqft17']>0, 1, 0)\n",
    "\n",
    "    #--- does the house have a pool?\n",
    "    dataframe['pooltypeid10'] = dataframe.pooltypeid10.fillna(0).astype(np.int8)\n",
    "    dataframe['pooltypeid7'] = dataframe.pooltypeid7.fillna(0).astype(np.int8)\n",
    "    dataframe['pooltypei2'] = dataframe.pooltypeid2.fillna(0).astype(np.int8)\n",
    "    dataframe['pool'] = dataframe['pooltypeid10'] | dataframe['pooltypeid7'] | dataframe['pooltypeid2']\n",
    "\n",
    "    #--- does the house have all of these? -> spa/hot-tub/pool, A/C, heating system , garage, patio\n",
    "    dataframe['exquisite'] = dataframe['pool'] + dataframe['patio'] + dataframe['garage'] + dataframe['heating_system'] + dataframe['AC']\n",
    "\n",
    "    #--- Features based on location ---\n",
    "    dataframe['x_loc'] = np.cos(dataframe['latitude']) * np.cos(dataframe['longitude'])\n",
    "    dataframe['y_loc'] = np.cos(dataframe['latitude']) * np.sin(dataframe['longitude'])\n",
    "    dataframe['z_loc'] = np.sin(dataframe['latitude'])\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def memory_reduce(dataframe):\n",
    "    #--- Memory usage of entire dataframe ---\n",
    "    mem = dataframe.memory_usage(index=True).sum()\n",
    "    print(\"Initial size {:.2f} MB\".format(mem/ 1024**2))\n",
    "\n",
    "    #--- List of columns that cannot be reduced in terms of memory size ---\n",
    "    count = 0\n",
    "    for c in dataframe.columns:\n",
    "        if dataframe[c].dtype == object:\n",
    "            count+=1\n",
    "    print('There are {} columns that cannot be reduced'.format(count))\n",
    "\n",
    "    count = 0\n",
    "    for c in dataframe.columns:\n",
    "        if dataframe[c].dtype != object:\n",
    "            if((c != 'logerror')|(c != 'yearbuilt')|(c != 'xloc')|(c != 'yloc')|(c != 'zloc')):\n",
    "                if ((dataframe[c].max() < 255) & (dataframe[c].min() > -255)):\n",
    "                    count+=1\n",
    "                    dataframe[c] = dataframe[c].fillna(0).astype(np.int8)\n",
    "                if ((dataframe[c].max() > 255) & (dataframe[c].min() > -255)\n",
    "                   & (dataframe[c].max() < 65535) & (dataframe[c].min() > 0)):\n",
    "                    count+=1\n",
    "                    dataframe[c] = dataframe[c].fillna(0).astype(np.int16)\n",
    "                if ((dataframe[c].max() > 65535) & (dataframe[c].min() > 0)\n",
    "                   & (dataframe[c].max() < 4294967295) & (dataframe[c].min() > 0)):\n",
    "                    count+=1\n",
    "                    dataframe[c] = dataframe[c].fillna(0).astype(np.int8)\n",
    "    print('There are {} columns reduced'.format(count))\n",
    "\n",
    "    #--- Let us check the memory consumed again ---\n",
    "    mem = dataframe.memory_usage(index=True).sum()\n",
    "    print(\"Final size {:.2f} MB\".format(mem/ 1024**2))\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(dataframe):\n",
    "    \n",
    "    dataframe['buildingclasstypeid'] = dataframe['buildingclasstypeid'].fillna(dataframe['buildingclasstypeid'].mode()[0])\n",
    "    dataframe['storytypeid'] = dataframe['storytypeid'].fillna(dataframe['storytypeid'].mode()[0])\n",
    "    dataframe['architecturalstyletypeid'] = dataframe['architecturalstyletypeid'].fillna(dataframe['architecturalstyletypeid'].mode()[0])\n",
    "    dataframe['typeconstructiontypeid'] = dataframe['typeconstructiontypeid'].fillna(dataframe['typeconstructiontypeid'].mode()[0])\n",
    "\n",
    "    dataframe['taxdelinquencyyear'] = dataframe['taxdelinquencyyear'].fillna(15).astype(np.int8)\n",
    "    dataframe['taxdelinquencyyear'] = np.where(dataframe.taxdelinquencyyear < 18, 2000 + dataframe.taxdelinquencyyear.astype(np.int16), 1900 + dataframe.taxdelinquencyyear.astype(np.int16)).astype(np.int16)\n",
    "\n",
    "    dataframe['taxamount'] = dataframe['taxamount'].fillna(dataframe['taxamount'].mean())\n",
    "\n",
    "    for c in dataframe.columns:\n",
    "        if 'squarefeet' in c or 'sqft' in c or 'size' in c or 'pooltypeid' in c or 'cnt' in c or 'nbr' in c or 'number' in c:\n",
    "            dataframe[c] = dataframe[c].fillna(0)\n",
    "    \n",
    "    #--- drop out ouliers ---\n",
    "#    dataframe = dataframe[dataframe.logerror > -0.4 ]\n",
    "#    dataframe = dataframe[dataframe.logerror < 0.4 ]\n",
    "\n",
    "# Deleting outliers\n",
    "# train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
    "    \n",
    "#     # replace or drop values ???\n",
    "#     for c in dataframe.columns:\n",
    "#         if c == 'logerror':\n",
    "#             ulimit = np.percentile(dataframe[c].values, 99)\n",
    "#             llimit = np.percentile(dataframe[c].values, 1)\n",
    "#             dataframe.loc[dataframe[c] > ulimit, [c]] = ulimit\n",
    "#             dataframe.loc[dataframe[c] < llimit, [c]] = llimit\n",
    "    \n",
    "    for c in dataframe.dtypes[dataframe.dtypes == object].index.values:\n",
    "        if len(dataframe[c].unique()) <= 2:\n",
    "            dataframe[c] = dataframe[c].map({True: 1, 'Y': 1})\n",
    "            dataframe[c] = dataframe[c].fillna(0)\n",
    "            dataframe[c] = dataframe[c].astype(np.int8)\n",
    "        else:\n",
    "            dataframe[c] = dataframe[c].fillna(1)\n",
    "            lbl = LabelEncoder()\n",
    "            lbl.fit(list(dataframe[c].values))\n",
    "            dataframe[c] = lbl.transform(list(dataframe[c].values)).astype(np.int8)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_selection(dataframe):\n",
    "    \n",
    "    x_train = df_train.drop(['parcelid', 'logerror'], axis=1)\n",
    "    x_train = x_train.fillna(0)\n",
    "    y_train = df_train['logerror'].values\n",
    "    x_col = list(x_train.columns)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    rfe = RFE(lr)\n",
    "    rfe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating new features ...\n",
      "Shape train: (90275, 60)\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 43.82 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 18.85 MB\n",
      "\n",
      "Creating training set ...\n",
      "(90275, 75) (90275,)\n",
      "\n",
      "Building DMatrix...\n",
      "\n",
      "Training ...\n",
      "[0]\ttrain-mae:0.00682563\ttest-mae:0.006833\n",
      "[10]\ttrain-mae:0.00673913\ttest-mae:0.00680825\n",
      "[20]\ttrain-mae:0.00667487\ttest-mae:0.0067935\n",
      "[30]\ttrain-mae:0.00662625\ttest-mae:0.0067965\n",
      "[40]\ttrain-mae:0.006599\ttest-mae:0.00681925\n",
      "[50]\ttrain-mae:0.00658525\ttest-mae:0.00685513\n",
      "[60]\ttrain-mae:0.00657113\ttest-mae:0.00688025\n",
      "[70]\ttrain-mae:0.00657012\ttest-mae:0.00693125\n",
      "[80]\ttrain-mae:0.00658537\ttest-mae:0.00700562\n",
      "[90]\ttrain-mae:0.00660137\ttest-mae:0.0070745\n",
      "[99]\ttrain-mae:0.00663188\ttest-mae:0.0071535\n",
      "Boost round parameter : 29\n",
      "\n",
      "Building test set ...\n",
      "\n",
      "Working batch 100000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 200000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 300000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 400000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 500000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 600000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 700000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 800000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 900000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1000000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1100000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1200000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1300000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1400000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1500000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1600000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1700000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 58 columns reduced\n",
      "Final size 152.78 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1800000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 1900000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2000000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 58 columns reduced\n",
      "Final size 152.78 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2100000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2200000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2300000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2400000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2500000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2600000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2700000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 59 columns reduced\n",
      "Final size 149.35 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2800000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 2900000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 326.16 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 60 columns reduced\n",
      "Final size 145.34 MB\n",
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Working batch 3000000\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "Initial size 277.94 MB\n",
      "There are 0 columns that cannot be reduced\n",
      "There are 55 columns reduced\n",
      "Final size 138.97 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting on test ...\n",
      "\n",
      "Writing csv ...\n",
      "\n",
      "Prediction available !!!\n",
      "CPU times: user 21min 51s, sys: 3min 1s, total: 24min 52s\n",
      "Wall time: 19min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('\\nLoading data ...')\n",
    "\n",
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "\n",
    "\n",
    "print('\\nCreating new features ...')\n",
    "\n",
    "df_train = pd.merge(train, prop, on='parcelid', how='left')\n",
    "print('Shape train: {}'.format(df_train.shape))\n",
    "\n",
    "df_train = create_newFeatures(df_train)\n",
    "\n",
    "\n",
    "print('\\nData preprocessing ...')\n",
    "\n",
    "df_train = data_preprocessing(df_train)\n",
    "\n",
    "\n",
    "print('\\nReducing consumption memory ...')\n",
    "\n",
    "df_train = memory_reduce(df_train)\n",
    "\n",
    "# print('\\nDropping columns ...')\n",
    "\n",
    "# col_2_drop = list(missing_ratio(df_train, plot=False).index)\n",
    "# df_train = df_train.drop(col_2_drop, axis=1)\n",
    "\n",
    "print('\\nCreating training set ...')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror'], axis=1)  # , 'propertyzoningdesc', 'propertycountylandusecode'\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "y_mean = np.mean(y_train)\n",
    "train_columns = x_train.columns\n",
    "    \n",
    "del df_train; gc.collect()\n",
    "\n",
    "# split = 80000\n",
    "# x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "# # x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.12, random_state=seed)\n",
    "\n",
    "print('\\nBuilding DMatrix...')\n",
    "\n",
    "# d_train = xgb.DMatrix(x_train, label=y_train)\n",
    "# d_valid = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "# del x_train, x_valid; gc.collect()\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, y_train)\n",
    "\n",
    "del x_train; gc.collect()\n",
    "\n",
    "print('\\nTraining ...')\n",
    "\n",
    "params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.80,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'silent': 1,\n",
    "    'seed': seed\n",
    "}\n",
    "\n",
    "# watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "# clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "#--- cross-validation ---\n",
    "cv_result = xgb.cv(\n",
    "                    params, \n",
    "                    d_train, \n",
    "                    nfold=8,\n",
    "                    num_boost_round=100,\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=10, \n",
    "                    show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = cv_result['test-mae-mean'].argmin()\n",
    "print('Boost round parameter : {}'.format(num_boost_rounds))\n",
    "\n",
    "#--- train model ---\n",
    "clf = xgb.train(dict(params), d_train, num_boost_round=num_boost_rounds)\n",
    "\n",
    "\n",
    "# del d_train, d_valid\n",
    "del d_train\n",
    "\n",
    "print('\\nBuilding test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "del prop, sample; gc.collect()\n",
    "\n",
    "p_test = []\n",
    "batch_size = 100000\n",
    "for batch in range(batch_size, df_test.shape[0]+batch_size, batch_size):\n",
    "    \n",
    "    print('\\nWorking batch {}'.format(batch))\n",
    "    \n",
    "    df_test_batch = df_test[batch-batch_size:batch].copy()\n",
    "    \n",
    "    print('\\nCreating new features ...')\n",
    "    \n",
    "    df_test_batch['rawcensustractandblock'] = df_test_batch.rawcensustractandblock.fillna(df_test.rawcensustractandblock.mode()[0])\n",
    "    df_test_batch = df_test_batch.fillna(0)\n",
    "    \n",
    "    df_test_batch = create_newFeatures(df_test_batch)\n",
    "    \n",
    "    print('\\nData preprocessing ...')\n",
    "\n",
    "    df_test_batch = data_preprocessing(df_test_batch)\n",
    "\n",
    "#    for c in df_test_batch.dtypes[df_test_batch.dtypes == object].index.values:\n",
    "#        df_test_batch[c] = df_test_batch[c].map({True: 1, 'Y': 1})\n",
    "#        df_test_batch[c] = df_test_batch[c].fillna(0).astype(np.int8)\n",
    "    \n",
    "    print('\\nReducing consumption memory ...')\n",
    "    \n",
    "    df_test_batch = memory_reduce(df_test_batch)\n",
    "\n",
    "    x_test = df_test_batch[train_columns]\n",
    "\n",
    "    del df_test_batch; gc.collect()\n",
    "\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "\n",
    "    del x_test; gc.collect()\n",
    "\n",
    "    print('\\nPredicting on test ...')\n",
    "\n",
    "    p_test_batch = clf.predict(d_test)\n",
    "\n",
    "    del d_test; gc.collect()\n",
    "    \n",
    "    [p_test.append(p) for p in p_test_batch]\n",
    "\n",
    "i = 0\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test[i::6]\n",
    "    i = i + 1\n",
    "\n",
    "print('\\nWriting csv ...')\n",
    "sub.to_csv('../submissions/xgb_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')\n",
    "\n",
    "print('\\nPrediction available !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParcelId</th>\n",
       "      <th>201610</th>\n",
       "      <th>201611</th>\n",
       "      <th>201612</th>\n",
       "      <th>201710</th>\n",
       "      <th>201711</th>\n",
       "      <th>201712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10754147</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10759547</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10843547</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.081253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10859147</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.061481</td>\n",
       "      <td>0.061481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10879947</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10898347</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10933547</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10940747</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024109</td>\n",
       "      <td>0.024109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10954547</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>0.257777</td>\n",
       "      <td>0.257777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10976347</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11073947</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.060466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11114347</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "      <td>0.658890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11116947</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11142747</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000895</td>\n",
       "      <td>-0.000895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11193347</td>\n",
       "      <td>0.507197</td>\n",
       "      <td>0.507197</td>\n",
       "      <td>0.507197</td>\n",
       "      <td>0.507197</td>\n",
       "      <td>0.507197</td>\n",
       "      <td>0.507197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11215747</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.115080</td>\n",
       "      <td>0.115080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11229347</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006191</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11287347</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11288547</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11324547</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11391347</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.024180</td>\n",
       "      <td>0.024180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11395747</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.043613</td>\n",
       "      <td>0.043613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11404347</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11405747</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11417147</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.004477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11457547</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>0.107994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11488147</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11520747</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.077396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11524947</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11544747</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.001425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985187</th>\n",
       "      <td>167636430</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985188</th>\n",
       "      <td>167690630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985189</th>\n",
       "      <td>167636630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985190</th>\n",
       "      <td>10834030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985191</th>\n",
       "      <td>167637430</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985192</th>\n",
       "      <td>167637630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985193</th>\n",
       "      <td>167637230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985194</th>\n",
       "      <td>11645030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985195</th>\n",
       "      <td>167689030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985196</th>\n",
       "      <td>167638630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985197</th>\n",
       "      <td>167638430</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985198</th>\n",
       "      <td>14342030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985199</th>\n",
       "      <td>167638230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985200</th>\n",
       "      <td>167637830</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985201</th>\n",
       "      <td>167639230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985202</th>\n",
       "      <td>14341030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985203</th>\n",
       "      <td>14341630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985204</th>\n",
       "      <td>14367630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985205</th>\n",
       "      <td>167638830</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985206</th>\n",
       "      <td>12572230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985207</th>\n",
       "      <td>14460030</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985208</th>\n",
       "      <td>14284830</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985209</th>\n",
       "      <td>14285230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985210</th>\n",
       "      <td>14455630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985211</th>\n",
       "      <td>11117630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985212</th>\n",
       "      <td>168176230</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985213</th>\n",
       "      <td>14273630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985214</th>\n",
       "      <td>168040630</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985215</th>\n",
       "      <td>168040830</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985216</th>\n",
       "      <td>168040430</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "      <td>0.114691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2985217 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ParcelId    201610    201611    201612    201710    201711    201712\n",
       "0         10754147  0.658890  0.658890  0.658890  0.658890  0.658890  0.658890\n",
       "1         10759547  0.002628  0.002628  0.002628  0.002628  0.002628  0.002628\n",
       "2         10843547  0.081253  0.081253  0.081253  0.081253  0.081253  0.081253\n",
       "3         10859147  0.061481  0.061481  0.061481  0.061481  0.061481  0.061481\n",
       "4         10879947  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "5         10898347  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "6         10933547  0.002628  0.002628  0.002628  0.002628  0.002628  0.002628\n",
       "7         10940747  0.024109  0.024109  0.024109  0.024109  0.024109  0.024109\n",
       "8         10954547  0.257777  0.257777  0.257777  0.257777  0.257777  0.257777\n",
       "9         10976347  0.004548  0.004548  0.004548  0.004548  0.004548  0.004548\n",
       "10        11073947  0.060466  0.060466  0.060466  0.060466  0.060466  0.060466\n",
       "11        11114347  0.658890  0.658890  0.658890  0.658890  0.658890  0.658890\n",
       "12        11116947  0.002628  0.002628  0.002628  0.002628  0.002628  0.002628\n",
       "13        11142747 -0.000895 -0.000895 -0.000895 -0.000895 -0.000895 -0.000895\n",
       "14        11193347  0.507197  0.507197  0.507197  0.507197  0.507197  0.507197\n",
       "15        11215747  0.115080  0.115080  0.115080  0.115080  0.115080  0.115080\n",
       "16        11229347  0.006191  0.006191  0.006191  0.006191  0.006191  0.006191\n",
       "17        11287347  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "18        11288547  0.001425  0.001425  0.001425  0.001425  0.001425  0.001425\n",
       "19        11324547  0.001425  0.001425  0.001425  0.001425  0.001425  0.001425\n",
       "20        11391347  0.024180  0.024180  0.024180  0.024180  0.024180  0.024180\n",
       "21        11395747  0.043613  0.043613  0.043613  0.043613  0.043613  0.043613\n",
       "22        11404347  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "23        11405747  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "24        11417147  0.004477  0.004477  0.004477  0.004477  0.004477  0.004477\n",
       "25        11457547  0.107994  0.107994  0.107994  0.107994  0.107994  0.107994\n",
       "26        11488147  0.001615  0.001615  0.001615  0.001615  0.001615  0.001615\n",
       "27        11520747  0.077396  0.077396  0.077396  0.077396  0.077396  0.077396\n",
       "28        11524947  0.001425  0.001425  0.001425  0.001425  0.001425  0.001425\n",
       "29        11544747  0.001425  0.001425  0.001425  0.001425  0.001425  0.001425\n",
       "...            ...       ...       ...       ...       ...       ...       ...\n",
       "2985187  167636430  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985188  167690630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985189  167636630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985190   10834030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985191  167637430  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985192  167637630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985193  167637230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985194   11645030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985195  167689030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985196  167638630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985197  167638430  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985198   14342030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985199  167638230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985200  167637830  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985201  167639230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985202   14341030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985203   14341630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985204   14367630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985205  167638830  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985206   12572230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985207   14460030  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985208   14284830  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985209   14285230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985210   14455630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985211   11117630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985212  168176230  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985213   14273630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985214  168040630  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985215  168040830  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "2985216  168040430  0.114691  0.114691  0.114691  0.114691  0.114691  0.114691\n",
       "\n",
       "[2985217 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
