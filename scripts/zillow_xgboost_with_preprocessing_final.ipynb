{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Kaggle Zillow Preprocessing + XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "###### 0.0660352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sami_function import missing_ratio\n",
    "from zillow_functions import create_newFeatures, data_preprocessing, memory_reduce, create_special_feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "from sklearn import linear_model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "seed = 42\n",
    "n_features = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (335776, 60)\n",
      "\n",
      "Data preprocessing ...\n",
      "\n",
      "\tOutliers treated ...\n",
      "\n",
      "Creating new features ...\n",
      "\n",
      "Reducing consumption memory ...\n",
      "\tInitial size 174.91 MB\n",
      "\tThere are 0 columns that cannot be reduced\n",
      "\tThere are 80 columns reduced\n",
      "\tFinal size 66.04 MB\n",
      "\n",
      "Creating training set ...\n",
      "(335776, 78) (335776,)\n",
      "\n",
      "Features selection ...\n",
      "\n",
      "Building DMatrix...\n",
      "\n",
      "Training ...\n",
      "[0]\ttrain-mae:0.0608598\ttest-mae:0.0608757\n",
      "[10]\ttrain-mae:0.0603333\ttest-mae:0.0604902\n",
      "[20]\ttrain-mae:0.0599594\ttest-mae:0.0602459\n",
      "[30]\ttrain-mae:0.0596873\ttest-mae:0.0600795\n",
      "[40]\ttrain-mae:0.0594723\ttest-mae:0.0599549\n",
      "[50]\ttrain-mae:0.0592927\ttest-mae:0.0598577\n",
      "[60]\ttrain-mae:0.0591338\ttest-mae:0.0597723\n",
      "[70]\ttrain-mae:0.0589947\ttest-mae:0.0597032\n",
      "[80]\ttrain-mae:0.0588748\ttest-mae:0.0596425\n",
      "[90]\ttrain-mae:0.058765\ttest-mae:0.0595884\n",
      "[100]\ttrain-mae:0.058665\ttest-mae:0.0595386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b1b3108d8d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'print(\\'\\\\nLoading data ...\\')\\n\\ntrain =  pd.read_csv(\\'../data/train_2016_v2.csv\\')\\ntrain17 =  pd.read_csv(\\'../data/train_2017.csv\\')\\nprop = pd.read_csv(\\'../data/properties_2016.csv\\')\\nsample = pd.read_csv(\\'../data/sample_submission.csv\\')\\nprop17 = pd.read_csv(\\'../data/properties_2017.csv\\', low_memory = False)\\n\\ntrain = pd.concat([train, train17])\\nprop = pd.concat([prop, prop17])\\ndf_train = pd.merge(train, prop, on=\\'parcelid\\', how=\\'left\\')\\nprint(\\'Shape train: {}\\'.format(df_train.shape))\\n\\ndel train; gc.collect()\\n\\nprint(\\'\\\\nData preprocessing ...\\')\\n\\ndf_train = data_preprocessing(df_train)\\n\\n\\nprint(\\'\\\\nCreating new features ...\\')\\n\\ndf_train = create_newFeatures(df_train)\\n\\n# New special feature\\ndates_model_col = [\\'transaction_year\\', \\'transaction_month\\', \\'yearbuilt\\', \\'house_age\\']\\ndf_train[\\'spe_feature\\'], datesFeature_mod = create_special_feature(df_train[dates_model_col], df_train[\\'logerror\\'].values)\\n\\n# Month feature\\nmonth_avgs = df_train.groupby(\\'transaction_month\\').agg([\\'mean\\'])[\\'logerror\\', \\'mean\\'].values - df_train[\\'logerror\\'].mean()\\nfrom sklearn.linear_model import LinearRegression\\nmonth_model = LinearRegression().fit(np.arange(4, 13, 1).reshape(-1, 1), \\n                                     month_avgs[3:].reshape(-1, 1))                       \\ndf_train[\\'super_month\\'] = month_model.predict(df_train[\\'transaction_month\\'].values.reshape(-1, 1))\\n\\n\\nprint(\\'\\\\nReducing consumption memory ...\\')\\n\\ndf_train = memory_reduce(df_train)\\n\\n# MAE 0.05255990000000001 for 50 rounds  [:39]\\n\\nprint(\\'\\\\nCreating training set ...\\')\\n\\nx_train = df_train.drop([\\'parcelid\\', \\'logerror\\'], axis=1)\\ny_train = df_train[\\'logerror\\'].values\\n\\nprint(x_train.shape, y_train.shape)\\n\\n\\nprint(\\'\\\\nFeatures selection ...\\')\\nfrom sklearn.feature_selection import RFE\\nfrom sklearn.linear_model import LinearRegression\\n\\nx_col = list(x_train.columns)\\nlr = LinearRegression()\\nrfe = RFE(lr)\\nrfe.fit(x_train, y_train)\\nx_val = [x[1] for x in [x for x in sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), x_col), reverse=True) if x[0] > 0]]\\n\\ntrain_columns = x_val[:n_features]\\nx_train = x_train[train_columns]\\ny_mean = np.mean(y_train)\\n\\n\\n#month_values = df_train[\\'transaction_month\\'].values\\n#x_train = np.hstack([x_train, month_model.predict(month_values.reshape(-1, 1))])\\n\\nsc = StandardScaler()\\nx_train = sc.fit_transform(x_train)\\n\\ndel df_train; gc.collect()\\n\\nprint(\\'\\\\nBuilding DMatrix...\\')\\n\\nd_train = xgb.DMatrix(x_train, y_train)\\n\\ndel x_train; gc.collect()\\n\\nprint(\\'\\\\nTraining ...\\')\\n\\nparams = {\\n    \\'learning_rate\\': 0.031,\\n    \\'max_depth\\': 9,\\n    \\'min_child_weight\\': 0,\\n    \\'gamma\\': 0.2,\\n    \\'subsample\\': 0.80,\\n    \\'n_estimators\\': 1000,\\n    \\'objective\\': \\'reg:linear\\',\\n    \\'eval_metric\\': \\'mae\\',\\n    \\'base_score\\': y_mean,\\n    \\'seed\\': seed\\n}\\n\\n# params = {\\n#     \\'colsample_bytree\\': 0.4603, \\n#     \\'gamma\\': 0.0468, \\n#     \\'learning_rate\\': 0.05, \\n#     \\'max_depth\\': 3, \\n#     \\'min_child_weight\\': 1.7817, \\n#     \\'n_estimators\\': 2200,\\n#     \\'reg_alpha\\': 0.4640, \\n#     \\'reg_lambda\\': 0.8571,\\n#     \\'subsample\\': 0.5213, \\n#     \\'silent\\': 1,\\n#     \\'random_state\\': 7, \\n#     \\'nthread\\': -1\\n# }\\n\\n#--- cross-validation ---\\ncv_result = xgb.cv(\\n                    params, \\n                    d_train, \\n                    nfold=10,\\n                    num_boost_round=1000,\\n                    early_stopping_rounds=100,\\n                    verbose_eval=10, \\n                    show_stdv=False\\n                  )\\n\\nnum_boost_rounds = cv_result[\\'test-mae-mean\\'].argmin()\\nmean_mae = cv_result[\\'test-mae-mean\\'].min()\\n\\nprint(\"\\\\n\\\\tMAE {} for {} rounds\".format(mean_mae, num_boost_rounds))\\n\\n#--- load best params GridSearch ---\\n# grid_clf = joblib.load(\\'xgboost_model.pkl\\')\\n\\n\\nprint(\\'\\\\nTraining model ...\\')\\nclf = xgb.train(dict(params), d_train, num_boost_round=num_boost_rounds)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[0;32m    404\u001b[0m                            evaluation_result_list=None))\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, iteration, fobj)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\xgboost-0.6-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 886\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    887\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('\\nLoading data ...')\n",
    "\n",
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "train17 =  pd.read_csv('../data/train_2017.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "prop17 = pd.read_csv('../data/properties_2017.csv', low_memory = False)\n",
    "\n",
    "train = pd.concat([train, train17])\n",
    "prop = pd.concat([prop, prop17])\n",
    "df_train = pd.merge(train, prop, on='parcelid', how='left')\n",
    "print('Shape train: {}'.format(df_train.shape))\n",
    "\n",
    "del train; gc.collect()\n",
    "\n",
    "print('\\nData preprocessing ...')\n",
    "\n",
    "df_train = data_preprocessing(df_train)\n",
    "\n",
    "\n",
    "print('\\nCreating new features ...')\n",
    "\n",
    "df_train = create_newFeatures(df_train)\n",
    "\n",
    "# New special feature\n",
    "dates_model_col = ['transaction_year', 'transaction_month', 'yearbuilt', 'house_age']\n",
    "df_train['spe_feature'], datesFeature_mod = create_special_feature(df_train[dates_model_col], df_train['logerror'].values)\n",
    "\n",
    "# Month feature\n",
    "month_avgs = df_train.groupby('transaction_month').agg(['mean'])['logerror', 'mean'].values - df_train['logerror'].mean()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "month_model = LinearRegression().fit(np.arange(4, 13, 1).reshape(-1, 1), \n",
    "                                     month_avgs[3:].reshape(-1, 1))                       \n",
    "df_train['super_month'] = month_model.predict(df_train['transaction_month'].values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "print('\\nReducing consumption memory ...')\n",
    "\n",
    "df_train = memory_reduce(df_train)\n",
    "\n",
    "# MAE 0.05255990000000001 for 50 rounds  [:39]\n",
    "\n",
    "print('\\nCreating training set ...')\n",
    "\n",
    "x_train = df_train.drop(['parcelid', 'logerror'], axis=1)\n",
    "y_train = df_train['logerror'].values\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "print('\\nFeatures selection ...')\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x_col = list(x_train.columns)\n",
    "lr = LinearRegression()\n",
    "rfe = RFE(lr)\n",
    "rfe.fit(x_train, y_train)\n",
    "x_val = [x[1] for x in [x for x in sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), x_col), reverse=True) if x[0] > 0]]\n",
    "\n",
    "train_columns = x_val[:n_features]\n",
    "x_train = x_train[train_columns]\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "\n",
    "#month_values = df_train['transaction_month'].values\n",
    "#x_train = np.hstack([x_train, month_model.predict(month_values.reshape(-1, 1))])\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "\n",
    "del df_train; gc.collect()\n",
    "\n",
    "print('\\nBuilding DMatrix...')\n",
    "\n",
    "d_train = xgb.DMatrix(x_train, y_train)\n",
    "\n",
    "del x_train; gc.collect()\n",
    "\n",
    "print('\\nTraining ...')\n",
    "\n",
    "params = {\n",
    "    'learning_rate': 0.031,\n",
    "    'max_depth': 9,\n",
    "    'min_child_weight': 0,\n",
    "    'gamma': 0.2,\n",
    "    'subsample': 0.80,\n",
    "    'n_estimators': 1000,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'base_score': y_mean,\n",
    "    'seed': seed\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'colsample_bytree': 0.4603, \n",
    "#     'gamma': 0.0468, \n",
    "#     'learning_rate': 0.05, \n",
    "#     'max_depth': 3, \n",
    "#     'min_child_weight': 1.7817, \n",
    "#     'n_estimators': 2200,\n",
    "#     'reg_alpha': 0.4640, \n",
    "#     'reg_lambda': 0.8571,\n",
    "#     'subsample': 0.5213, \n",
    "#     'silent': 1,\n",
    "#     'random_state': 7, \n",
    "#     'nthread': -1\n",
    "# }\n",
    "\n",
    "#--- cross-validation ---\n",
    "cv_result = xgb.cv(\n",
    "                    params, \n",
    "                    d_train, \n",
    "                    nfold=10,\n",
    "                    num_boost_round=1000,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=10, \n",
    "                    show_stdv=False\n",
    "                  )\n",
    "\n",
    "num_boost_rounds = cv_result['test-mae-mean'].argmin()\n",
    "mean_mae = cv_result['test-mae-mean'].min()\n",
    "\n",
    "print(\"\\n\\tMAE {} for {} rounds\".format(mean_mae, num_boost_rounds))\n",
    "\n",
    "#--- load best params GridSearch ---\n",
    "# grid_clf = joblib.load('xgboost_model.pkl')\n",
    "\n",
    "\n",
    "print('\\nTraining model ...')\n",
    "clf = xgb.train(dict(params), d_train, num_boost_round=num_boost_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "# clf = xgb.train(params, d_train, 10000, watchlist, early_stopping_rounds=100, verbose_eval=10)\n",
    "\n",
    "del d_train\n",
    "\n",
    "print('\\nBuilding test set ...')\n",
    "\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')\n",
    "\n",
    "del prop, sample; gc.collect()\n",
    "\n",
    "p_test = []\n",
    "batch_size = 100000\n",
    "for batch in range(batch_size, df_test.shape[0]+batch_size, batch_size):\n",
    "    \n",
    "    print('\\nWorking batch {}'.format(batch))\n",
    "    \n",
    "    df_test_batch = df_test[batch-batch_size:batch].copy()\n",
    "    \n",
    "    print('\\nData preprocessing ...')\n",
    "    \n",
    "    df_test_batch['rawcensustractandblock'] = df_test_batch.rawcensustractandblock.fillna(df_test.rawcensustractandblock.mode()[0])\n",
    "    df_test_batch = data_preprocessing(df_test_batch)\n",
    "    df_test_batch = df_test_batch.fillna(1)\n",
    "    \n",
    "    print('\\nCreating new features ...')\n",
    "    \n",
    "    df_test_batch = create_newFeatures(df_test_batch)\n",
    "    df_test_batch['spe_feature'], nawFeature_mod = create_special_feature(df_test_batch[dates_model_col], model=datesFeature_mod)\n",
    "    df_test_batch['super_month'] = month_model.predict(df_test_batch['transaction_month'].values.reshape(-1, 1))\n",
    "    \n",
    "    print('\\nReducing consumption memory ...')\n",
    "    \n",
    "    df_test_batch = memory_reduce(df_test_batch)\n",
    "\n",
    "    x_test_batch = df_test_batch[train_columns]\n",
    "    #x_test_batch = np.hstack([x_test_batch, np.zeros((x_test_batch.shape[0], 1))])\n",
    "    x_test_batch = sc.transform(x_test_batch)\n",
    "    \n",
    "    del df_test_batch; gc.collect()\n",
    "\n",
    "    d_test = xgb.DMatrix(x_test_batch)\n",
    "\n",
    "    del x_test_batch; gc.collect()\n",
    "\n",
    "    print('\\nPredicting on test ...')\n",
    "\n",
    "    p_test_batch = clf.predict(d_test)\n",
    "\n",
    "    del d_test; gc.collect()\n",
    "    \n",
    "    [p_test.append(p) for p in p_test_batch]\n",
    "\n",
    "i = 0\n",
    "sub = pd.read_csv('../data/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    sub[c] = p_test[i::6]\n",
    "    i = i + 1\n",
    "\n",
    "print('\\nWriting csv ...')\n",
    "sub.to_csv('../submissions/xgb_{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False, float_format='%.4f')\n",
    "\n",
    "print('\\nPrediction available !!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WBirmingham\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train: (335776, 60)\n"
     ]
    }
   ],
   "source": [
    "train =  pd.read_csv('../data/train_2016_v2.csv')\n",
    "train17 =  pd.read_csv('../data/train_2017.csv')\n",
    "prop = pd.read_csv('../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../data/sample_submission.csv')\n",
    "prop17 = pd.read_csv('../data/properties_2017.csv', low_memory = False)\n",
    "\n",
    "train = pd.concat([train, train17])\n",
    "prop = pd.concat([prop, prop17])\n",
    "df_train = pd.merge(train, prop, on='parcelid', how='left')\n",
    "print('Shape train: {}'.format(df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAE 0.05216269999999999 for 89 rounds # waiting for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAE 0.0521541 for 104 rounds # with special feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAE 0.05215620000000001 for 72 rounds # standadScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAE 0.052151499999999996 for 96 rounds # standadScaler with special feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAE 0.052151499999999996 for 96 rounds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
